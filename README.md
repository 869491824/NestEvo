# NestEvo
# NestEvo——高精度增益的多终端模型与全局模型协同演化(自适应)优化与演化加速框架

Organization: Northwestern Polytechnical University

Author: Lehao Wang,Sicong Liu, Zhiwen Yu, Haoyi Yu, Bin Guo

To appear at Chinese Journal of Computers 2024

[[`Paper`](https://facebookresearch.github.io/ImageBind/paper)] [[`CSDN`](https://ai.facebook.com/blog/imagebind-six-modalities-binding-ai/)] [[`github`](https://imagebind.metademolab.com/)] [[`gitee`](https://dl.fbaipublicfiles.com/imagebind/imagebind_video.mp4)] [[`开源中国`](https://dl.fbaipublicfiles.com/imagebind/imagebind_video.mp4)] [[`CrowdHMT`](https://dl.fbaipublicfiles.com/imagebind/imagebind_video.mp4)] [[`BibTex`](#citing-imagebind)]

## 问题

### 概述

基于深度学习的视频分析不可避免地会面临数据漂移问题，即真实场景的视频数据与模型训练数据不相符，数据漂移会降低模型的推理精度，对于部署在终端的模型尤为严重，边缘辅助的模型持续演化（自适应）是一种理想解决方式，即边缘辅助器收集来自终端设备的数据，利用边缘的高精度golden model（教师模型）进行基于迁移学习的终端模型微调以实现模型演化（自适应）。但是我们发现数据漂移也会对golden model的精度造成影响，从而影响终端模型的学习效果。

*NestEvo* 提出一个高精度增益的多终端模型与全局模型协同演化优化与演化加速框架，一方面通过基于互学习的多终端模型演化方法，增强演化中的知识交互和共进学习，实现多个终端模型与全局模型的协同在线演化，另一方面利用基于存内计算的异构硬件加速方案，减少大量的访存开销，改善存算隔离带来的延迟，从而加快系统整体演化速度



## 动机

尽管研究者对边缘辅助的模型持续演化进行了广泛的研究，但将其仍存在两个问题：

- 现有深度模型演化系统通常只关注如何提高终端模型的推理精度，而面对更为复杂的多终端演化情景时，全局模型也会受到数据漂移的影响导致输出的监督标签质量下降，影响终端模型演化效果。
- 已有工作通常忽略了系统演化延迟对于终端模型长生命周期内平均推理精度的影响，导致终端长时间以低精度模型运行，影响用户体验

## 系统设计

### 系统概述

*NestEvo* 系统图如图1所示，其创新设计包括两个模块：

- 多终端互学习共进演化方法: 通过互学习增强演化中多终端的知识交互和共进学习，改善全局模型提供的监督信号置信度和终端模型的演化精度增益，提升受到数据漂移影响的长生命周期终端模型推理精度；

- 多终端并发演化任务调度与存内计算加速方案: 通过存内计算架构加快多终端互学习共进演化速度，提升终端模型全生命周期的平均推理精度。同时，针对GPU存储特点和存内计算噪声明显的缺点，我们通过自适应数据压缩机制和模型训练优化，在加速模型演化的同时保证精度

 ![image](https://github.com/user-attachments/assets/572ec199-851d-414e-b3e0-366c46a51246)
 图1.NestEvo系统示意图


### 模块功能

#### 多终端互学习共进演化方法:

为了高效提升受到数据漂移影响后的终端模型的推理精度，*NestEvo* 采用的多终端互学习共进演化方法能够针对多终端数据漂移情况，自适应的触发仅终端模型演化或终端模型与全局模型协同在线演化，伪代码算法2所示。

具体来说，不同的多个移动终端将筛选后的视频帧上传至边缘服务器，由于较大的参数体积和较强的泛化能力，全局模型相比于终端模型对数据漂移有着一定的鲁棒性。为了避免过多的冗余更新，降低资源占用和演化延迟，我们基于漂移检测的结果使系统自适应地触发不同的演化策略：仅终端模型演化或终端模型和全局模型的协同演化。当触发仅终端模型演化时，只需进行知识蒸馏即可完成演化任务。而当触发终端模型和全局模型协同演化时，我们为每个终端模型配备一个与全局模型配置相同的中间模型，利用终端模型和中间模型的互学习首先完成中间模型的训练更新。

在此过程中利用数据生成，减少各个终端数据特征分布之间的搬土距离，在保留原本数据特征的基础上，使每个终端模型-中间模型组合学习到的视频数据特征分布趋于近似，从而缓解数据分布异构的影响。之后将中间模型聚合生成全局模型完成全局模型的更新。中间模型的引入可以将终端模型和全局模型相互隔离，全局模型不再由终端模型聚合生成，因此，避免了任务模型异构的影响。最后，利用新的全局模型为终端模型进行知识蒸馏即可完成全部演化任务。

![image](https://github.com/user-attachments/assets/9102980c-5149-457d-95c2-fed88907fabf)



#### 多终端并发演化任务调度与存内计算加速方案: 

为了尽快完成新的高精度终端模型的演化部署，*NestEvo* 为基于互学习的多终端压缩模型在线演化系统设计了一套基于存内计算的模型演化异构硬件加速方案以降低演化延迟，提高终端模型的平均推理精度。

首先，*NestEvo* 针对并发的多终端演化训练任务进行任务调度，在充分利用边缘服务器有限硬件资源的同时减少所有任务的平均等待时间。具体来说，任务调度中包括任务分析器和任务调度器。

- 任务分析器：*NestEvo* 以任务训练特征（批量大小、训练周期等）为输入，利用任务分析器可以预测得到每个任务的性能指标（显存占用和训练时间）。

- 任务调度器：以任务分析器的结果作为的输入，*NestEvo*可以筛选出优先级最高的任务组合率先提供演化服务。每当有任务完成时，*NestEvo*会从等待任务中选择新的任务组合，直到所有任务完成为止。

​	基于多终端演化任务调度的输出结果， *NestEvo* 提出了基于存内计算的异构模型演化训练加速方案以缩减多终端并发演化任务的训练时间，从而进一步减少演化延迟。

- GPU加速器：当触发仅终端模型演化时，只需进行知识蒸馏即可完成演化任务，此时NestEvo利用GPU加速终端模型的训练速度，实现终端模型的稳定有效演化。而当触发终端模型和全局模型协同演化时，GPU负责终端模型和中间模型的互学习以及终端模型的知识蒸馏训练加速。与此同时，我们对GPU加速训练中的数据进行自适应压缩，减少数据冗余，从而降低了GPU显存开销，减少了GPU加速训练的演化延迟。

- 存内计算加速器：其负责全局模型的输出加速，并利用模型训练优化提升全局模型的权重噪声鲁棒性。存内计算可以利用高效的矩阵乘法大幅度加快全局模型推理速度，更快为终端模型和中间模型训练提供监督信号，加快系统整体演化速度。但是，存内计算在实现高效推理加速的同时，模型推理会受到电导噪声的影响，导致精度下降。我们利用互学习特性以及模型训练优化手段提升了演化后新的全局模型的权重噪声鲁棒性，降低了全局模型的推理精度损失并提高了输出稳定性，使软硬件更加适配，提高系统的整体性能。





## 实验结果

将该的系统与四种基线进行比较，即*域适应*、*没有数据生成的 NestEvo*、*原始终端 模型* 和 *单终端自适应*。在这个实验中，*NestEvo*采用了三种类型的终端和轻量级深度学习模型，即修剪后的Faster-RCNN，在受到数据漂移影响后，三个模型的精度下降为为0.441，0.315 和 0.437。使用这些终端在移动场景中收集的视频，*NestEvo*比较了演化（自适应）后的深度学习模型的精度增益，如表xxx所示。*NestEvo*在准确度方面取得了最佳的整体性能，与原始终端模型相比，平均准确率提高了 40% 以上，而全局模型的平均准确率提高了 9.13%。

![image](https://github.com/user-attachments/assets/8f802fe5-f877-4e81-8cfa-1add1b8c313c)






## Citing AdaEvo

If you find this repository useful, please consider giving a citation

```
@article{ JSJX20240104001,
author = { 王乐豪 and  刘思聪 and  於志文 and  于昊艺 and  郭斌 },
title = {一种多终端视频流智能识别模型共进演化方法研究},
journal = {计算机学报},
pages = {1-26},
issn = {0254-4164},
}
```



